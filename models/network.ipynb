{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import torch as t\n",
    "from ipynb.fs.full.module import BasicModule\n",
    "from torch.nn.functional import grid_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     21,
     39,
     61,
     78
    ]
   },
   "outputs": [],
   "source": [
    "def guidedSlice(grid, guide):\n",
    "    # get coordinates for interpolation\n",
    "    batch, _, hei, wid = guide.size()\n",
    "    grid_y, grid_x = t.meshgrid([\n",
    "        t.arange(0, hei, device=grid.device),\n",
    "        t.arange(0, wid, device=grid.device)\n",
    "    ])\n",
    "    grid_y = grid_y.repeat(batch, 1, 1).unsqueeze(3) / (hei - 1) * 2 - 1\n",
    "    grid_x = grid_x.repeat(batch, 1, 1).unsqueeze(3) / (wid - 1) * 2 - 1\n",
    "    guide = guide.permute(0, 2, 3, 1).contiguous()\n",
    "    guide_grid = t.cat([guide, grid_y, grid_x], dim=3).unsqueeze(1)\n",
    "\n",
    "    # 3d slicing\n",
    "    samples = grid_sample(grid,\n",
    "                          guide_grid,\n",
    "                          mode='bilinear',\n",
    "                          align_corners=True)\n",
    "\n",
    "    return samples.squeeze(2)\n",
    "\n",
    "\n",
    "class dpConv2d(BasicModule):\n",
    "    def __init__(self, in_chns, out_chns, stride, padding):\n",
    "        super(dpConv2d, self).__init__()\n",
    "        self.feats = t.nn.Sequential(\n",
    "            t.nn.Conv2d(in_chns,\n",
    "                        in_chns,\n",
    "                        3,\n",
    "                        stride=stride,\n",
    "                        padding=padding,\n",
    "                        groups=in_chns,\n",
    "                        bias=False), t.nn.ReLU(inplace=True),\n",
    "            t.nn.Conv2d(in_chns, out_chns, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.feats(x)\n",
    "\n",
    "\n",
    "class invResidual(BasicModule):\n",
    "    def __init__(self, in_chns, out_chns, stride):\n",
    "        super(invResidual, self).__init__()\n",
    "\n",
    "        inter_chns = in_chns * 6\n",
    "        self.feats = t.nn.Sequential(t.nn.Conv2d(in_chns, inter_chns, 1),\n",
    "                                     t.nn.ReLU(inplace=True),\n",
    "                                     dpConv2d(inter_chns, out_chns, stride, 1))\n",
    "        if stride == 1 and in_chns == out_chns:\n",
    "            self.add_res = True\n",
    "        else:\n",
    "            self.add_res = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.add_res:\n",
    "\n",
    "            return x + self.feats(x)\n",
    "        else:\n",
    "\n",
    "            return self.feats(x)\n",
    "\n",
    "\n",
    "class bottleNeck(BasicModule):\n",
    "    def __init__(self, in_chns, out_chns, stride, repeats):\n",
    "        super(bottleNeck, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        for index in range(0, repeats):\n",
    "            if index == 0:\n",
    "                layers.append(invResidual(in_chns, out_chns, stride))\n",
    "            else:\n",
    "                layers.append(invResidual(out_chns, out_chns, 1))\n",
    "        self.feats = t.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.feats(x)\n",
    "\n",
    "\n",
    "class Enhancer(BasicModule):\n",
    "    def __init__(self, pretrain=True, z_res=16, ilm_iter=9, clr_pcc=60):\n",
    "        super(Enhancer, self).__init__()\n",
    "        if pretrain == True:\n",
    "            self.model_name = 'Enhancer_final'\n",
    "        else:\n",
    "            self.model_name = 'Enhancer_pretrain'\n",
    "\n",
    "        # model settings\n",
    "        self.z_res = z_res  # z-axis resolution\n",
    "        self.ilm_iter = ilm_iter  # number of iteration\n",
    "        self.clr_pcc = clr_pcc  # number of polynominal coefficients\n",
    "\n",
    "        # feature extraction\n",
    "        self.feats = t.nn.Sequential(t.nn.Conv2d(3, 32, 3, padding=1),\n",
    "                                     t.nn.ReLU(inplace=True),\n",
    "                                     dpConv2d(32, 16, 1, 1),\n",
    "                                     bottleNeck(16, 24, 2, 2),\n",
    "                                     bottleNeck(24, 32, 2, 3),\n",
    "                                     bottleNeck(32, 64, 2, 4),\n",
    "                                     bottleNeck(64, 96, 1, 3),\n",
    "                                     bottleNeck(96, 160, 2, 3))\n",
    "\n",
    "        # illumination path\n",
    "        self.ilm_loc = t.nn.Sequential(t.nn.Conv2d(160, 96, 3, padding=1),\n",
    "                                       t.nn.ReLU(inplace=True),\n",
    "                                       t.nn.Conv2d(96, 96, 3, padding=1),\n",
    "                                       t.nn.ReLU(inplace=True),\n",
    "                                       t.nn.Conv2d(96, 96, 3, padding=1))\n",
    "        self.ilm_glb = t.nn.Sequential(\n",
    "            t.nn.Conv2d(160, 96, 3, stride=2, padding=1),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Conv2d(96,\n",
    "                                                 96,\n",
    "                                                 3,\n",
    "                                                 stride=2,\n",
    "                                                 padding=1),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Conv2d(96,\n",
    "                                                 96,\n",
    "                                                 3,\n",
    "                                                 stride=2,\n",
    "                                                 padding=1),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Flatten(), t.nn.Linear(384, 256),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Linear(256, 128),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Linear(128, 96), t.nn.Sigmoid())\n",
    "        self.ilm_out = t.nn.Sequential(\n",
    "            t.nn.ReLU(inplace=True),\n",
    "            t.nn.Conv2d(96, self.z_res * self.ilm_iter, 1))\n",
    "        self.ilm_map = t.nn.Sequential(t.nn.Conv2d(3, 32, 3, padding=1),\n",
    "                                       t.nn.ReLU(inplace=True),\n",
    "                                       t.nn.Conv2d(32, 32, 3, padding=1),\n",
    "                                       t.nn.ReLU(inplace=True),\n",
    "                                       t.nn.Conv2d(32, 1, 3, padding=1),\n",
    "                                       t.nn.Tanh())\n",
    "\n",
    "        # color path\n",
    "        self.clr_out = t.nn.Sequential(\n",
    "            t.nn.Conv2d(160, 96, 3, stride=2, padding=1),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Conv2d(96,\n",
    "                                                 96,\n",
    "                                                 3,\n",
    "                                                 stride=2,\n",
    "                                                 padding=1),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Conv2d(96,\n",
    "                                                 96,\n",
    "                                                 3,\n",
    "                                                 stride=2,\n",
    "                                                 padding=1),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Flatten(), t.nn.Linear(384, 256),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Linear(256, 128),\n",
    "            t.nn.ReLU(inplace=True), t.nn.Linear(128, self.clr_pcc))\n",
    "\n",
    "    def forward(self, down_img, full_img):\n",
    "        # extract features\n",
    "        shared_feat = self.feats(down_img)\n",
    "\n",
    "        # ilmination enhancement branch\n",
    "        ilm_loc = self.ilm_loc(shared_feat)\n",
    "        ilm_glb = self.ilm_glb(shared_feat)\n",
    "        ilm_glb = ilm_glb.view(-1, 96, 1, 1)\n",
    "        ilm_grid = self.ilm_out(ilm_loc * ilm_glb)\n",
    "        ilm_grid = ilm_grid.view(-1, self.ilm_iter, self.z_res, 16, 16)\n",
    "        ilm_guide = self.ilm_map(full_img)\n",
    "\n",
    "        # bilateral umsapling\n",
    "        ilm_coes = guidedSlice(ilm_grid, ilm_guide)\n",
    "\n",
    "        # clr enhancement branch\n",
    "        clr_coes = self.clr_out(shared_feat)\n",
    "\n",
    "        return ilm_coes, clr_coes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     21,
     40,
     70,
     87
    ]
   },
   "outputs": [],
   "source": [
    "class sptAtt(BasicModule):\n",
    "    def __init__(self):\n",
    "        super(sptAtt, self).__init__()\n",
    "\n",
    "        # point weights\n",
    "        self.weights = t.nn.Sequential(t.nn.Conv2d(2, 1, 3, padding=1),\n",
    "                                       t.nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # global max pooling\n",
    "        gmp_maps = t.max(x, 1)[0].unsqueeze(1)\n",
    "\n",
    "        # global average pooling\n",
    "        gap_maps = t.mean(x, 1).unsqueeze(1)\n",
    "\n",
    "        # get weights\n",
    "        weight = self.weights(t.cat([gmp_maps, gap_maps], dim=1))\n",
    "\n",
    "        return x * weight\n",
    "\n",
    "\n",
    "class chnAtt(BasicModule):\n",
    "    def __init__(self, n_feats, reduction=16):\n",
    "        super(chnAtt, self).__init__()\n",
    "\n",
    "        # channel weights\n",
    "        intp_feats = n_feats // reduction\n",
    "        self.weights = t.nn.Sequential(t.nn.AdaptiveAvgPool2d(1),\n",
    "                                       t.nn.Conv2d(n_feats, intp_feats, 1),\n",
    "                                       t.nn.ReLU(inplace=True),\n",
    "                                       t.nn.Conv2d(intp_feats, n_feats, 1),\n",
    "                                       t.nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get weights\n",
    "        weight = self.weights(x)\n",
    "\n",
    "        return x * weight\n",
    "\n",
    "\n",
    "class dualAttBlk(BasicModule):\n",
    "    def __init__(self, n_feats):\n",
    "        super(dualAttBlk, self).__init__()\n",
    "\n",
    "        # feature extraction\n",
    "        self.feats = t.nn.Sequential(\n",
    "            t.nn.Conv2d(n_feats, n_feats, 3, padding=1), t.nn.PReLU(n_feats),\n",
    "            t.nn.Conv2d(n_feats, n_feats, 3, padding=1))\n",
    "\n",
    "        # dual attentions\n",
    "        self.spt_att = sptAtt()\n",
    "        self.chn_att = chnAtt(n_feats)\n",
    "\n",
    "        # output residual\n",
    "        self.res = t.nn.Conv2d(n_feats * 2, n_feats, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # extract features\n",
    "        feats = self.feats(x)\n",
    "\n",
    "        # get attention maps\n",
    "        spt_maps = self.spt_att(feats)\n",
    "        chn_maps = self.chn_att(feats)\n",
    "\n",
    "        # get residual maps\n",
    "        res = self.res(t.cat([spt_maps, chn_maps], dim=1))\n",
    "\n",
    "        return x + res\n",
    "\n",
    "\n",
    "class recResBlk(BasicModule):\n",
    "    def __init__(self, n_feats, num_dab):\n",
    "        super(recResBlk, self).__init__()\n",
    "\n",
    "        # output residual\n",
    "        modules = []\n",
    "        modules = [dualAttBlk(n_feats) for _ in range(num_dab)]\n",
    "        modules.append(t.nn.Conv2d(n_feats, n_feats, 3, padding=1))\n",
    "        self.res = t.nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get residual maps\n",
    "        res = self.res(x)\n",
    "\n",
    "        return x + res\n",
    "\n",
    "\n",
    "class Denoiser(BasicModule):\n",
    "    def __init__(self, cam_model, num_rrg=6, num_dab=2, n_feats=64):\n",
    "        super(Denoiser, self).__init__()\n",
    "        self.model_name = 'Denoiser_%s' % cam_model\n",
    "\n",
    "        head_modules = [t.nn.Conv2d(12, n_feats, 3, padding=1)]\n",
    "\n",
    "        body_modules = [\n",
    "            recResBlk(n_feats, num_dab=num_dab) for _ in range(num_rrg)\n",
    "        ]\n",
    "        body_modules.append(t.nn.Conv2d(n_feats, n_feats, 3, padding=1))\n",
    "        body_modules.append(t.nn.PReLU(n_feats))\n",
    "\n",
    "        tail_modules = [t.nn.Conv2d(n_feats, 4, 3, padding=1)]\n",
    "\n",
    "        self.head = t.nn.Sequential(*head_modules)\n",
    "        self.body = t.nn.Sequential(*body_modules)\n",
    "        self.tail = t.nn.Sequential(*tail_modules)\n",
    "\n",
    "        # convolutional LSTM\n",
    "        self.lstm_f = t.nn.Sequential(\n",
    "            t.nn.Conv2d(n_feats * 2, n_feats, 3, padding=1), t.nn.Sigmoid())\n",
    "        self.lstm_i = t.nn.Sequential(\n",
    "            t.nn.Conv2d(n_feats * 2, n_feats, 3, padding=1), t.nn.Sigmoid())\n",
    "        self.lstm_g = t.nn.Sequential(\n",
    "            t.nn.Conv2d(n_feats * 2, n_feats, 3, padding=1), t.nn.Tanh())\n",
    "        self.lstm_o = t.nn.Sequential(\n",
    "            t.nn.Conv2d(n_feats * 2, n_feats, 3, padding=1), t.nn.Sigmoid())\n",
    "\n",
    "    def forward(self, in_img, noise_map, img_res=None):\n",
    "        # head features\n",
    "        if img_res is None:\n",
    "            feat = self.head(\n",
    "                t.cat([in_img, noise_map,\n",
    "                       t.zeros_like(in_img)], dim=1))\n",
    "        else:\n",
    "            feat = self.head(t.cat([in_img, noise_map, img_res], dim=1))\n",
    "\n",
    "        # initialize hidden states\n",
    "        if img_res is None:\n",
    "            img_res = t.zeros_like(in_img)\n",
    "            self.state_h = t.zeros_like(feat)\n",
    "            self.state_c = t.zeros_like(feat)\n",
    "\n",
    "        # back projection\n",
    "        feat = t.cat([feat, self.state_h], dim=1)\n",
    "        self.state_c = self.lstm_f(feat) * self.state_c + self.lstm_i(\n",
    "            feat) * self.lstm_g(feat)\n",
    "        self.state_h = self.lstm_o(feat) * t.tanh(self.state_c)\n",
    "\n",
    "        feat = self.state_h + self.body(self.state_h)\n",
    "\n",
    "        out_img = self.tail(feat)\n",
    "        out_img = t.clamp(out_img, 0.0, 1.0)\n",
    "\n",
    "        return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Discriminator(BasicModule):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model_name = 'Discriminator'\n",
    "\n",
    "        # feature extraction\n",
    "        self.feats = t.nn.Sequential(\n",
    "            t.nn.Conv2d(6, 8, 4, stride=2, padding=1), t.nn.ReLU(),\n",
    "            t.nn.Conv2d(8, 16, 4, stride=2, padding=1), t.nn.ReLU(),\n",
    "            t.nn.Conv2d(16, 32, 4, stride=2, padding=1), t.nn.ReLU(),\n",
    "            t.nn.Conv2d(32, 64, 4, stride=2, padding=1), t.nn.ReLU(),\n",
    "            t.nn.Conv2d(64, 128, 4, stride=2, padding=1), t.nn.ReLU(),\n",
    "            t.nn.Conv2d(128, 256, 4, stride=2, padding=1), t.nn.ReLU(),\n",
    "            t.nn.Conv2d(256, 512, 4, stride=2, padding=1), t.nn.ReLU(),\n",
    "            t.nn.Flatten(), t.nn.Linear(2048, 256), t.nn.ReLU(),\n",
    "            t.nn.Linear(256, 128), t.nn.ReLU(), t.nn.Linear(128, 1))\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        out_label = self.feats(t.cat([img1, img2], dim=1))\n",
    "\n",
    "        return out_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
