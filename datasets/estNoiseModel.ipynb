{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Noise Model Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import os\n",
    "import pickle\n",
    "import pyexiv2 as exiv2\n",
    "import numpy as np\n",
    "import rawpy as rp\n",
    "import scipy.stats as stat\n",
    "import multiprocessing as par\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint as pp\n",
    "from matplotlib import rc\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# path to dataset\n",
    "data_root = '/home/lab/Documents/SSD/PlieCNR/cameras/DJI'\n",
    "\n",
    "# set font type and size\n",
    "# font = {'family': 'Times New Roman', 'weight': 'normal', 'size': 14}\n",
    "# rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# make folder to saves\n",
    "save_root = os.path.join(data_root, 'noiseModel')\n",
    "if not os.path.exists(save_root):\n",
    "    os.makedirs(save_root)\n",
    "\n",
    "# get file list\n",
    "data_folder = os.path.join(data_root, 'noise')\n",
    "file_list = [\n",
    "    file for file in os.listdir(data_folder) if '.dng' or '.DNG' in file\n",
    "]\n",
    "file_list.sort()\n",
    "\n",
    "cam_iso_list = {}\n",
    "noise_profile_list = {}\n",
    "for file in file_list:\n",
    "    # read metadata\n",
    "    img_md = exiv2.ImageMetadata(os.path.join(data_folder, file))\n",
    "    img_md.read()\n",
    "\n",
    "    # extract metadata\n",
    "    cam_iso = None\n",
    "    cam_noise = None\n",
    "    for key in img_md:\n",
    "        if 'ISOSpeedRatings' in key:\n",
    "            cam_iso = img_md[key].value\n",
    "            continue\n",
    "\n",
    "        if 'NoiseProfile' in key:\n",
    "            cam_noise = img_md[key].raw_value.split()\n",
    "            cam_noise = np.array(cam_noise, dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "    if cam_iso is None:\n",
    "        raise AttributeError('No ISOSpeedRatings found.')\n",
    "    elif cam_noise is None:\n",
    "        raise AttributeError('No NoiseProfile found.')\n",
    "    else:\n",
    "        print(file, 'ISO:', cam_iso, 'Noise:', cam_noise[:2])\n",
    "\n",
    "    # add to list\n",
    "    if cam_iso in cam_iso_list:\n",
    "        cam_iso_list[cam_iso].append(file)\n",
    "    else:\n",
    "        cam_iso_list[cam_iso] = [file]\n",
    "\n",
    "    if cam_iso not in noise_profile_list:\n",
    "        noise_profile_list[cam_iso] = cam_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate noise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     40
    ]
   },
   "outputs": [],
   "source": [
    "# requires dark image\n",
    "def estNoiseModel(img_seq, a=-0.5, b=0.5, figs=[]):\n",
    "    row_noise = []\n",
    "    read_noise = []\n",
    "    noise_model = {}\n",
    "    for img in img_seq:\n",
    "        row_mean = np.mean(img, axis=1)\n",
    "        row_noise.append(row_mean)\n",
    "        img = img - row_mean.reshape(-1, 1)\n",
    "        read_noise.append(img)\n",
    "    row_noise = np.array(row_noise).flatten()\n",
    "    read_noise = np.array(read_noise).flatten()\n",
    "\n",
    "    # fit row noise model\n",
    "    loc, scale = stat.norm.fit(row_noise)\n",
    "    noise_model['sig_r'] = scale\n",
    "\n",
    "    # fit read noise model\n",
    "    if len(figs) > 0:\n",
    "        ax1 = figs[0].add_subplot(1, 1, 1)\n",
    "        ax2 = figs[1].add_subplot(1, 1, 1)\n",
    "    else:\n",
    "        ax1 = None\n",
    "        ax2 = None\n",
    "    shape, ppcc = stat.ppcc_plot(read_noise, a, b, plot=ax1)\n",
    "    lam = shape[np.argmax(ppcc)]\n",
    "    ax1.vlines(lam, 0, 1, colors='r')\n",
    "    noise_model['lam_tl'] = lam\n",
    "\n",
    "    _, result = stat.probplot(read_noise,\n",
    "                              sparams=(lam, ),\n",
    "                              dist=stat.tukeylambda,\n",
    "                              plot=ax2)\n",
    "    noise_model['sig_tl'] = result[0]\n",
    "    noise_model['r_tl'] = result[2]\n",
    "\n",
    "    return noise_model\n",
    "\n",
    "\n",
    "# process given ISO\n",
    "def processISO(cam_iso):\n",
    "    # estimate noise models\n",
    "    file_list = cam_iso_list[cam_iso]\n",
    "\n",
    "    img_seq = []\n",
    "    for file in file_list:\n",
    "        # read raw image\n",
    "        with rp.imread(os.path.join(data_folder, file)) as raw_obj:\n",
    "            raw_img = raw_obj.raw_image_visible.copy()\n",
    "            raw_img = raw_img.astype(np.float32)\n",
    "            mask = raw_obj.raw_colors_visible\n",
    "            blk_level = raw_obj.black_level_per_channel\n",
    "            sat_level = raw_obj.white_level\n",
    "\n",
    "        # normalize to 0-1\n",
    "        raw_img[mask == 0] = raw_img[mask == 0] - blk_level[0]\n",
    "        raw_img[mask == 1] = raw_img[mask == 1] - blk_level[1]\n",
    "        raw_img[mask == 2] = raw_img[mask == 2] - blk_level[2]\n",
    "        raw_img[mask == 3] = raw_img[mask == 3] - blk_level[3]\n",
    "        raw_img = raw_img / float(sat_level - max(blk_level))\n",
    "        img_seq.append(raw_img)\n",
    "\n",
    "    # estimate noise model\n",
    "    fig0 = plt.figure()\n",
    "    fig1 = plt.figure()\n",
    "    noise_model = estNoiseModel(img_seq, figs=[fig0, fig1])\n",
    "    noise_model['k'] = noise_profile_list[cam_iso][0]\n",
    "    noise_model['hf_step'] = 0.5 / float(sat_level)\n",
    "\n",
    "    # save figures\n",
    "    save_path = os.path.join(\n",
    "        save_root,\n",
    "        'ISO%d_PPCC.png' % cam_iso,\n",
    "    )\n",
    "    fig0.savefig(save_path, bbox_inches='tight')\n",
    "    save_path = os.path.join(save_root, 'ISO%d_PP.png' % cam_iso)\n",
    "    fig1.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return cam_iso, noise_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# requires estimated noise models\n",
    "def linearFit(data_x, data_y):\n",
    "    # compute slope and constant\n",
    "    x_mean = np.mean(data_x)\n",
    "    y_mean = np.mean(data_y)\n",
    "    xy_diff = np.sum((data_x - x_mean) * (data_y - y_mean))\n",
    "    x_diff2 = np.sum((data_x - x_mean)**2)\n",
    "\n",
    "    slope = xy_diff / x_diff2\n",
    "    const = y_mean - slope * x_mean\n",
    "\n",
    "    # compute standard deviation\n",
    "    length = data_x.shape[0]\n",
    "    x_sum = np.sum(data_x)\n",
    "    y_sum = np.sum(data_y)\n",
    "    xy_sum = np.sum(data_x * data_y)\n",
    "    x_sum2 = np.sum(data_x)**2\n",
    "    y_sum2 = np.sum(data_y)**2\n",
    "    xy_sum2 = np.sum(data_x * data_y)**2\n",
    "    x2_sum = np.sum(data_x**2)\n",
    "    y2_sum = np.sum(data_y**2)\n",
    "\n",
    "    std = y2_sum - (length * xy_sum2 + y_sum2 * x2_sum -\n",
    "                    2 * x_sum * y_sum * xy_sum) / (length * x2_sum - x_sum2)\n",
    "    std = std / (length - 2)\n",
    "\n",
    "    return slope, const, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit noise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# estimate noise models\n",
    "cores = par.cpu_count()\n",
    "pool = par.Pool(processes=cores)\n",
    "model_list = {}\n",
    "iso_seq = [cam_iso for cam_iso in cam_iso_list]\n",
    "\n",
    "for (cam_iso, noise_model) in tqdm(pool.imap(processISO, iso_seq),\n",
    "                                   desc='progress',\n",
    "                                   total=len(iso_seq)):\n",
    "    model_list[cam_iso] = noise_model\n",
    "    print('Estimation of ISO%d completed.' % cam_iso)\n",
    "pool.close()\n",
    "\n",
    "# save estimated noise models\n",
    "save_path = os.path.join(save_root, 'model_params.pkl')\n",
    "with open(save_path, 'wb') as pkl:\n",
    "    pickle.dump(model_list, pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# plot a line from slope and intercept\n",
    "def abline(fig, slope, intercept):\n",
    "    axes = fig.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# take log\n",
    "k_list = []\n",
    "sig_r_list = []\n",
    "sig_tl_list = []\n",
    "lam_tl_list = []\n",
    "for cam_iso in model_list:\n",
    "    k_list.append(model_list[cam_iso]['k'])\n",
    "    sig_r_list.append(model_list[cam_iso]['sig_r'])\n",
    "    sig_tl_list.append(model_list[cam_iso]['sig_tl'])\n",
    "    lam_tl_list.append(model_list[cam_iso]['lam_tl'])\n",
    "\n",
    "k_list = np.log(np.array(k_list))\n",
    "sig_r_list = np.log(np.array(sig_r_list))\n",
    "sig_tl_list = np.log(np.array(sig_tl_list))\n",
    "lam_tl_mean = np.mean(lam_tl_list)\n",
    "hf_step = model_list[list(model_list.keys())[0]]['hf_step']\n",
    "\n",
    "# linear regression\n",
    "r_s, r_c, r_std = linearFit(k_list, sig_r_list)\n",
    "tl_s, tl_c, tl_std = linearFit(k_list, sig_tl_list)\n",
    "\n",
    "# print results\n",
    "print(\n",
    "    \"Stat info for row noise {'slope': %f, 'const': %f, 'std': %e, 'min': %f, 'max': %f}\"\n",
    "    % (r_s, r_c, r_std, np.min(k_list), np.max(k_list)))\n",
    "print(\n",
    "    \"Stat info for read noise {'slope': %f, 'const': %f, 'std': %e, 'min': %f, 'max': %f}\"\n",
    "    % (tl_s, tl_c, tl_std, np.min(k_list), np.max(k_list)))\n",
    "\n",
    "# plot results\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(1, 1, 1)\n",
    "ax1.plot(k_list, sig_r_list, 'bo', markersize=3)\n",
    "abline(fig1, r_s, r_c)\n",
    "plt.xlabel('$\\log(K)$')\n",
    "plt.ylabel('$\\log(\\sigma_{r})$')\n",
    "plt.close()\n",
    "\n",
    "fig2 = plt.figure()\n",
    "ax2 = fig2.add_subplot(1, 1, 1)\n",
    "ax2.plot(k_list, sig_tl_list, 'bo', markersize=3)\n",
    "abline(fig2, tl_s, tl_c)\n",
    "plt.xlabel('$\\log(K)$')\n",
    "plt.ylabel('$\\log(\\sigma_{TL})$')\n",
    "plt.close()\n",
    "\n",
    "# save to figures\n",
    "save_path = os.path.join(save_root, 'row_fit.png')\n",
    "fig1.savefig(save_path, bbox_inches='tight')\n",
    "save_path = os.path.join(save_root, 'read_fit.png')\n",
    "fig2.savefig(save_path, bbox_inches='tight')\n",
    "\n",
    "# save statistics\n",
    "model_stats = {}\n",
    "model_stats['hf_step'] = hf_step\n",
    "model_stats['lam_tl'] = lam_tl_mean\n",
    "model_stats['k'] = (np.min(k_list), np.max(k_list))\n",
    "model_stats['sig_r'] = (r_s, r_c, r_std)\n",
    "model_stats['sig_tl'] = (tl_s, tl_c, tl_std)\n",
    "save_path = os.path.join(save_root, 'model_stats.pkl')\n",
    "with open(save_path, 'wb') as pkl:\n",
    "    pickle.dump(model_stats, pkl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
