{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import os, sys, warnings\n",
    "import ipdb\n",
    "import torch as t\n",
    "import torchnet as tnt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# add paths for all sub-folders\n",
    "paths = [root for root, _, _ in os.walk('.') if 'evals' not in root]\n",
    "for item in paths:\n",
    "    sys.path.append(item)\n",
    "\n",
    "from ipynb.fs.full.config import Config\n",
    "from ipynb.fs.full.monitor import Visualizer\n",
    "from ipynb.fs.full.network import *\n",
    "from ipynb.fs.full.dataLoader import *\n",
    "from ipynb.fs.full.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for debugging only\n",
    "%pdb off\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# choose GPU if available\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load configuration\n",
    "opt = Config('paired')\n",
    "\n",
    "# dataset for training\n",
    "train_set = PairedSet(opt)\n",
    "train_loader = t.utils.data.DataLoader(train_set,\n",
    "                                       batch_size=opt.batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=opt.num_workers,\n",
    "                                       pin_memory=True)\n",
    "\n",
    "# visualizer\n",
    "vis = Visualizer(env='paired', port=8686)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_E = Enhancer(pretrain=False).to(device)\n",
    "net_E_optim = t.optim.Adam(net_E.parameters(), lr=opt.lr)\n",
    "net_E_sched = t.optim.lr_scheduler.StepLR(net_E_optim,\n",
    "                                          step_size=opt.upd_freq[0],\n",
    "                                          gamma=opt.lr_decay)\n",
    "mse_loss = t.nn.MSELoss()\n",
    "net_E_meter = tnt.meter.AverageValueMeter()\n",
    "\n",
    "# start training\n",
    "for epoch in tqdm(range(opt.max_epoch[0]),\n",
    "                  desc='epoch',\n",
    "                  total=opt.max_epoch[0]):\n",
    "    # reset meters and update learning rate\n",
    "    net_E_meter.reset()\n",
    "    net_E_sched.step()\n",
    "\n",
    "    for (in_img, out_img) in train_loader:\n",
    "        # copy to device\n",
    "        in_img = in_img.to(device)\n",
    "        out_img = out_img.to(device)\n",
    "\n",
    "        # downsample\n",
    "        in_img = downsize(in_img)\n",
    "        out_img = downsize(out_img)\n",
    "\n",
    "        # reset gradient\n",
    "        net_E_optim.zero_grad()\n",
    "\n",
    "        # train generator\n",
    "        ilm_coes, clr_coes = net_E(in_img, in_img)\n",
    "        pred_ilm_img = applyIlmCoes(in_img, ilm_coes)\n",
    "        pred_clr_img = applyClrCoes(pred_ilm_img, clr_coes)\n",
    "\n",
    "        # convert to graycale bt averaging three channels\n",
    "        pred_avg_img = t.mean(pred_ilm_img, dim=1, keepdim=True)\n",
    "        gt_avg_img = t.mean(in_img, dim=1, keepdim=True)\n",
    "        gt_avg_img = t.where(gt_avg_img <= 0.0031308, 12.92 * gt_avg_img,\n",
    "                             1.055 * (gt_avg_img**(1 / 2.4)) - 0.055)\n",
    "\n",
    "        # compute generator loss\n",
    "        net_E_loss = (mse_loss(pred_avg_img, gt_avg_img) +\n",
    "                      mse_loss(pred_clr_img, out_img)) / 2\n",
    "\n",
    "        # update generator\n",
    "        net_E_loss.backward()\n",
    "        net_E_optim.step()\n",
    "\n",
    "        # add to loss meter for logging\n",
    "        net_E_meter.add(net_E_loss.item())\n",
    "\n",
    "    # show training status\n",
    "    if epoch + 1 > 5:\n",
    "        vis.plot('loss (net_E)', net_E_meter.value()[0])\n",
    "        disp_img = t.clamp(t.cat([pred_avg_img, gt_avg_img], dim=-1), 0.0,\n",
    "                           1.0)[0, :, :, :]\n",
    "        vis.img('pred illum/gt', disp_img.cpu() * 255)\n",
    "        disp_img = t.clamp(t.cat([pred_clr_img, out_img], dim=-1), 0.0,\n",
    "                           1.0)[0, :, :, :]\n",
    "        vis.img('pred color/gt', disp_img.cpu() * 255)\n",
    "\n",
    "    # save models\n",
    "    if (epoch + 1) % opt.save_freq == 0:\n",
    "        net_E.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_D = Discriminator().to(device)\n",
    "net_D_optim = t.optim.Adam(net_D.parameters(), lr=opt.lr)\n",
    "net_D_sched = t.optim.lr_scheduler.StepLR(net_D_optim,\n",
    "                                          step_size=opt.upd_freq[1],\n",
    "                                          gamma=opt.lr_decay)\n",
    "bce_loss = t.nn.BCEWithLogitsLoss()\n",
    "net_D_meter = tnt.meter.AverageValueMeter()\n",
    "\n",
    "# set generator to eval mode\n",
    "net_E.eval()\n",
    "for param in net_E.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# start training\n",
    "for epoch in tqdm(range(opt.max_epoch[1]),\n",
    "                  desc='epoch',\n",
    "                  total=opt.max_epoch[1]):\n",
    "    # reset meters and update learning rate\n",
    "    net_D_meter.reset()\n",
    "    net_D_sched.step()\n",
    "\n",
    "    for (in_img, out_img) in train_loader:\n",
    "        # copy to device\n",
    "        in_img = in_img.to(device)\n",
    "        out_img = out_img.to(device)\n",
    "\n",
    "        # downsample\n",
    "        in_img = downsize(in_img)\n",
    "        out_img = downsize(out_img)\n",
    "\n",
    "        # inference\n",
    "        with t.no_grad():\n",
    "            ilm_coes, _ = net_E(in_img, in_img)\n",
    "            ilm_img = applyIlmCoes(in_img, ilm_coes)\n",
    "            ilm_img = ilm_img.detach()\n",
    "\n",
    "        # reset gradient\n",
    "        net_D_optim.zero_grad()\n",
    "\n",
    "        # train discriminator\n",
    "        pred_real = net_D(ilm_img, out_img)\n",
    "        pred_fake = net_D(out_img, ilm_img)\n",
    "\n",
    "        # compute discriminator loss\n",
    "        net_D_loss = (bce_loss(pred_real, t.ones_like(pred_real)) +\n",
    "                      bce_loss(pred_fake, t.zeros_like(pred_fake))) / 2\n",
    "\n",
    "        # update discriminator\n",
    "        net_D_loss.backward()\n",
    "        net_D_optim.step()\n",
    "\n",
    "        # add to loss meter for logging\n",
    "        net_D_meter.add(net_D_loss.item())\n",
    "\n",
    "    # show training status\n",
    "    if epoch + 1 > 5:\n",
    "        vis.plot('loss (net_D)', net_D_meter.value()[0])\n",
    "\n",
    "    # save models\n",
    "    if (epoch + 1) % opt.save_freq == 0:\n",
    "        net_D.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
